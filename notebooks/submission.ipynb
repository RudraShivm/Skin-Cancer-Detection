{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ISIC 2024 — Skin Cancer Detection (Inference Only)\n",
                "\n",
                "**This notebook is for Kaggle submission only.** It loads pre-trained checkpoints\n",
                "from attached datasets, processes test images + tabular metadata, and generates\n",
                "`submission.csv`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CONFIGURATION — Edit these for your setup\n",
                "# ============================================================\n",
                "import os, sys, warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Map of model_name -> Kaggle dataset slug where its checkpoints live.\n",
                "# When you add a notebook output as a dataset, Kaggle mounts it at:\n",
                "#   /kaggle/input/{dataset-slug}/\n",
                "USERNAME = \"rudrashivm\"\n",
                "MODEL_DATASETS = {\n",
                "    \"efficientnet_b0\": f\"{USERNAME}/efficientnet-b0\",\n",
                "    # \"convnext_tiny\":   \"convnext-tiny\",\n",
                "    # \"swin_large\":      \"swin-large\",\n",
                "}\n",
                "\n",
                "ENSEMBLE_STRATEGY = \"soft\"   # \"soft\" or \"hard_weighted\"\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "# Competition data\n",
                "DATA_DIR = \"/kaggle/input/isic-2024-challenge\"\n",
                "TEST_HDF5 = os.path.join(DATA_DIR, \"test-image.hdf5\")\n",
                "TEST_META = os.path.join(DATA_DIR, \"test-metadata.csv\")\n",
                "SAMPLE_SUB = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
                "OUTPUT_DIR = \"/kaggle/working\"\n",
                "\n",
                "# Verify data sources\n",
                "print(\"Data sources:\")\n",
                "for path, label in [(TEST_HDF5, \"test HDF5\"), (TEST_META, \"test metadata\"), (SAMPLE_SUB, \"sample submission\")]:\n",
                "    status = \"\\u2705\" if os.path.exists(path) else \"\\u274c\"\n",
                "    print(f\"  {status} {label}: {path}\")\n",
                "\n",
                "print(\"\\nCheckpoint datasets:\")\n",
                "for model_name, dataset_slug in MODEL_DATASETS.items():\n",
                "    base = f\"/kaggle/input/datasets/{dataset_slug}\"\n",
                "    ckpt_dir = os.path.join(base, \"checkpoints\", model_name)\n",
                "    status = \"\\u2705\" if os.path.exists(ckpt_dir) else \"\\u274c\"\n",
                "    print(f\"  {status} {model_name}: {ckpt_dir}\")\n",
                "    if os.path.exists(ckpt_dir):\n",
                "        for fold_dir in sorted(os.listdir(ckpt_dir)):\n",
                "            fold_path = os.path.join(ckpt_dir, fold_dir)\n",
                "            if os.path.isdir(fold_path):\n",
                "                ckpts = [f for f in os.listdir(fold_path) if f.endswith('.ckpt')]\n",
                "                print(f\"      {fold_dir}: {ckpts}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# MODEL, TRANSFORMS & TABULAR ENCODING (self-contained)\n",
                "# ============================================================\n",
                "# Everything needed to load checkpoints and run inference.\n",
                "# Mirrors src/models/isic_module.py, src/data/components/transforms.py,\n",
                "# and tabular encoding from src/data/isic_datamodule.py.\n",
                "# Fully inline so the notebook works without internet.\n",
                "# ============================================================\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import timm\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "\n",
                "try:\n",
                "    from lightning import LightningModule\n",
                "except ImportError:\n",
                "    from pytorch_lightning import LightningModule\n",
                "\n",
                "from torchmetrics import MaxMetric, MeanMetric\n",
                "from torchmetrics.classification import BinaryAUROC, BinaryROC\n",
                "from typing import Any, Dict, List, Tuple\n",
                "\n",
                "\n",
                "def get_val_transforms(img_size: int = 384):\n",
                "    \"\"\"Validation/test transforms: resize + normalize.\"\"\"\n",
                "    return A.Compose([\n",
                "        A.Resize(img_size, img_size),\n",
                "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "        ToTensorV2(),\n",
                "    ])\n",
                "\n",
                "\n",
                "# === Tabular feature encoding (must match isic_datamodule.py exactly) ===\n",
                "TABULAR_NUM_COLS = [\n",
                "    'age_approx', 'clin_size_long_diam_mm',\n",
                "    'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext',\n",
                "    'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext',\n",
                "    'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2',\n",
                "    'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean',\n",
                "    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL',\n",
                "    'tbp_lv_deltaLB', 'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity',\n",
                "    'tbp_lv_minorAxisMM', 'tbp_lv_nevi_confidence',\n",
                "    'tbp_lv_norm_border', 'tbp_lv_norm_color', 'tbp_lv_perimeterMM',\n",
                "    'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt',\n",
                "    'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
                "    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
                "    'tbp_lv_dnn_lesion_confidence',\n",
                "]\n",
                "\n",
                "\n",
                "def encode_tabular(df: pd.DataFrame) -> np.ndarray:\n",
                "    \"\"\"Encode tabular features identically to ISICDataModule._encode_tabular.\"\"\"\n",
                "    parts = []\n",
                "    # Numeric\n",
                "    num_data = df[TABULAR_NUM_COLS].fillna(0).values.astype(np.float32)\n",
                "    parts.append(num_data)\n",
                "    # Sex -> binary\n",
                "    sex_map = {'male': 1.0, 'female': 0.0}\n",
                "    sex_vals = df['sex'].map(sex_map).fillna(0.5).values.astype(np.float32).reshape(-1, 1)\n",
                "    parts.append(sex_vals)\n",
                "    # Anatomical site -> one-hot\n",
                "    site_categories = [\n",
                "        'head/neck', 'upper extremity', 'lower extremity',\n",
                "        'anterior torso', 'posterior torso', 'lateral torso', 'palms/soles'\n",
                "    ]\n",
                "    site_encoded = np.zeros((len(df), len(site_categories)), dtype=np.float32)\n",
                "    for i, cat in enumerate(site_categories):\n",
                "        site_encoded[:, i] = (df['anatom_site_general'] == cat).astype(np.float32)\n",
                "    parts.append(site_encoded)\n",
                "    return np.hstack(parts)\n",
                "\n",
                "\n",
                "class ISICLitModule(LightningModule):\n",
                "    \"\"\"ISICLitModule matching the training checkpoint structure.\n",
                "    Supports both image-only and image+tabular fusion modes.\"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        name: str = \"\",\n",
                "        backbone: str = \"tf_efficientnet_b0_ns\",\n",
                "        num_classes: int = 1,\n",
                "        pretrained: bool = False,\n",
                "        lr: float = 1e-4,\n",
                "        weight_decay: float = 1e-2,\n",
                "        max_epochs: int = 20,\n",
                "        dropout: float = 0.0,\n",
                "        pos_weight: float = 1.0,\n",
                "        n_tabular_features: int = 0,\n",
                "    ):\n",
                "        super().__init__()\n",
                "        self.save_hyperparameters(logger=False)\n",
                "\n",
                "        if n_tabular_features > 0:\n",
                "            self.model = timm.create_model(\n",
                "                backbone, pretrained=False, num_classes=0, drop_rate=dropout,\n",
                "            )\n",
                "            img_feat_dim = self.model.num_features\n",
                "            fusion_dim = img_feat_dim + n_tabular_features\n",
                "            self.fusion_head = nn.Sequential(\n",
                "                nn.Linear(fusion_dim, 128),\n",
                "                nn.BatchNorm1d(128),\n",
                "                nn.ReLU(inplace=True),\n",
                "                nn.Dropout(dropout),\n",
                "                nn.Linear(128, 1),\n",
                "            )\n",
                "        else:\n",
                "            self.model = timm.create_model(\n",
                "                backbone, pretrained=False, num_classes=num_classes, drop_rate=dropout,\n",
                "            )\n",
                "            self.fusion_head = None\n",
                "\n",
                "        self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]))\n",
                "        self.train_auroc = BinaryAUROC()\n",
                "        self.val_auroc = BinaryAUROC()\n",
                "        self.test_auroc = BinaryAUROC()\n",
                "        self.val_roc = BinaryROC()\n",
                "        self.train_loss = MeanMetric()\n",
                "        self.val_loss = MeanMetric()\n",
                "        self.test_loss = MeanMetric()\n",
                "        self.val_auroc_best = MaxMetric()\n",
                "        self.register_buffer(\"best_threshold\", torch.tensor(0.5))\n",
                "        self.register_buffer(\"best_auroc\", torch.tensor(0.0))\n",
                "        self._val_preds = []\n",
                "        self._val_targets = []\n",
                "\n",
                "    def forward(self, x, tabular=None):\n",
                "        if self.fusion_head is not None and tabular is not None:\n",
                "            img_features = self.model(x)\n",
                "            combined = torch.cat([img_features, tabular], dim=1)\n",
                "            return self.fusion_head(combined)\n",
                "        else:\n",
                "            return self.model(x)\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
                "\n",
                "\n",
                "def get_model_img_size(model):\n",
                "    \"\"\"Auto-detect image size from TIMM backbone config.\"\"\"\n",
                "    try:\n",
                "        data_config = timm.data.resolve_data_config(model.model.pretrained_cfg)\n",
                "        return data_config.get(\"input_size\", (3, 224, 224))[-1]\n",
                "    except Exception:\n",
                "        return 384\n",
                "\n",
                "\n",
                "print(\"\\u2705 Model, transforms, and tabular encoding defined\")\n",
                "print(f\"   Tabular features: {len(TABULAR_NUM_COLS)} numeric + 1 sex + 7 site = {len(TABULAR_NUM_COLS) + 8} total\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# INFERENCE — Load checkpoints, predict on test-image.hdf5\n",
                "# ============================================================\n",
                "\n",
                "import h5py, cv2, glob\n",
                "from tqdm import tqdm\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# Load test metadata\n",
                "test_meta_df = pd.read_csv(TEST_META, low_memory=False)\n",
                "sample_sub = pd.read_csv(SAMPLE_SUB)\n",
                "isic_ids = sample_sub[\"isic_id\"].tolist()\n",
                "print(f\"Test samples: {len(isic_ids)}\")\n",
                "\n",
                "# Encode tabular features for test set\n",
                "# Reorder test_meta_df to match isic_ids order from sample_submission\n",
                "test_meta_df = test_meta_df.set_index('isic_id').loc[isic_ids].reset_index()\n",
                "test_tabular_raw = encode_tabular(test_meta_df)\n",
                "print(f\"Tabular features shape: {test_tabular_raw.shape}\")\n",
                "\n",
                "# Note: tabular standardization uses approximate stats.\n",
                "# For best results, save training stats during training and load them here.\n",
                "# For now, we self-standardize the test set (acceptable approximation).\n",
                "tab_mean = test_tabular_raw.mean(axis=0)\n",
                "tab_std = test_tabular_raw.std(axis=0)\n",
                "tab_std[tab_std < 1e-7] = 1.0\n",
                "test_tabular = (test_tabular_raw - tab_mean) / tab_std\n",
                "\n",
                "# ---- Discover and load all model checkpoints ----\n",
                "model_configs = []  # List of (model, img_size, threshold, auroc, uses_tabular)\n",
                "\n",
                "for model_name, dataset_slug in MODEL_DATASETS.items():\n",
                "    ckpt_base = f\"/kaggle/input/datasets/{dataset_slug}/checkpoints/{model_name}\"\n",
                "    if not os.path.isdir(ckpt_base):\n",
                "        print(f\"\\u26a0\\ufe0f  Skipping {model_name}: {ckpt_base} not found\")\n",
                "        continue\n",
                "    \n",
                "    fold_dirs = sorted([\n",
                "        d for d in os.listdir(ckpt_base)\n",
                "        if d.startswith(\"fold_\") and os.path.isdir(os.path.join(ckpt_base, d))\n",
                "    ])\n",
                "    \n",
                "    print(f\"\\n{model_name}: {len(fold_dirs)} folds\")\n",
                "    \n",
                "    for fold_dir in fold_dirs:\n",
                "        fold_path = os.path.join(ckpt_base, fold_dir)\n",
                "        auroc_ckpts = sorted(glob.glob(os.path.join(fold_path, \"epoch_*_auroc_*.ckpt\")))\n",
                "        if auroc_ckpts:\n",
                "            def get_auroc(p):\n",
                "                try: return float(os.path.basename(p).split(\"auroc_\")[-1].replace(\".ckpt\",\"\"))\n",
                "                except: return 0.0\n",
                "            ckpt_path = max(auroc_ckpts, key=get_auroc)\n",
                "        elif os.path.exists(os.path.join(fold_path, \"last.ckpt\")):\n",
                "            ckpt_path = os.path.join(fold_path, \"last.ckpt\")\n",
                "        else:\n",
                "            any_ckpts = glob.glob(os.path.join(fold_path, \"*.ckpt\"))\n",
                "            ckpt_path = any_ckpts[0] if any_ckpts else None\n",
                "        \n",
                "        if ckpt_path is None:\n",
                "            print(f\"  {fold_dir}: no checkpoint found\")\n",
                "            continue\n",
                "        \n",
                "        print(f\"  {fold_dir}: {os.path.basename(ckpt_path)}\")\n",
                "        model = ISICLitModule.load_from_checkpoint(ckpt_path, map_location=device, strict=False)\n",
                "        model.eval()\n",
                "        model.to(device)\n",
                "        \n",
                "        img_size = get_model_img_size(model)\n",
                "        threshold = model.best_threshold.item()\n",
                "        auroc = model.best_auroc.item() if hasattr(model, \"best_auroc\") else 0.5\n",
                "        uses_tabular = model.fusion_head is not None\n",
                "        print(f\"    img_size={img_size}, threshold={threshold:.4f}, auroc={auroc:.4f}, tabular={uses_tabular}\")\n",
                "        \n",
                "        model_configs.append((model, img_size, threshold, auroc, uses_tabular))\n",
                "\n",
                "print(f\"\\nTotal model-folds loaded: {len(model_configs)}\")\n",
                "assert len(model_configs) > 0, \"No checkpoints loaded! Check MODEL_DATASETS paths.\"\n",
                "\n",
                "# ---- Run inference ----\n",
                "hdf5 = h5py.File(TEST_HDF5, \"r\")\n",
                "\n",
                "all_probs = []\n",
                "all_thresholds = []\n",
                "all_aurocs = []\n",
                "\n",
                "for model_idx, (model, img_size, threshold, auroc, uses_tabular) in enumerate(model_configs):\n",
                "    print(f\"\\nModel {model_idx+1}/{len(model_configs)} (img_size={img_size}, tabular={uses_tabular})...\")\n",
                "    transform = get_val_transforms(img_size)\n",
                "    probs = []\n",
                "    \n",
                "    for batch_start in tqdm(range(0, len(isic_ids), BATCH_SIZE), desc=\"Batches\"):\n",
                "        batch_ids = isic_ids[batch_start : batch_start + BATCH_SIZE]\n",
                "        batch_images = []\n",
                "        \n",
                "        for isic_id in batch_ids:\n",
                "            img_bytes = hdf5[isic_id][()]\n",
                "            img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
                "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "            img = transform(image=img)[\"image\"]\n",
                "            batch_images.append(img)\n",
                "        \n",
                "        batch_tensor = torch.stack(batch_images).to(device)\n",
                "        \n",
                "        # Prepare tabular features for this batch if model uses them\n",
                "        if uses_tabular:\n",
                "            batch_tab = torch.tensor(\n",
                "                test_tabular[batch_start : batch_start + len(batch_ids)],\n",
                "                dtype=torch.float32\n",
                "            ).to(device)\n",
                "        else:\n",
                "            batch_tab = None\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            logits = model(batch_tensor, batch_tab).squeeze(1)\n",
                "            batch_probs = torch.sigmoid(logits).cpu().numpy()\n",
                "        probs.extend(batch_probs.tolist())\n",
                "    \n",
                "    all_probs.append(np.array(probs))\n",
                "    all_thresholds.append(threshold)\n",
                "    all_aurocs.append(auroc)\n",
                "    \n",
                "    del model\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.empty_cache()\n",
                "\n",
                "hdf5.close()\n",
                "\n",
                "# ---- Ensemble ----\n",
                "all_probs = np.array(all_probs)\n",
                "\n",
                "if ENSEMBLE_STRATEGY == \"hard_weighted\":\n",
                "    weights = np.array(all_aurocs)\n",
                "    weights = weights / weights.sum() if weights.sum() > 0 else np.ones_like(weights) / len(weights)\n",
                "    hard = np.array([(p >= t).astype(float) for p, t in zip(all_probs, all_thresholds)])\n",
                "    final_probs = np.average(hard, axis=0, weights=weights)\n",
                "    final_threshold = 0.5\n",
                "    print(f\"\\nHard-weighted ensemble | weights: {[f'{w:.3f}' for w in weights]}\")\n",
                "else:\n",
                "    final_probs = np.mean(all_probs, axis=0)\n",
                "    final_threshold = np.mean(all_thresholds)\n",
                "    print(f\"\\nSoft ensemble | threshold: {final_threshold:.4f}\")\n",
                "\n",
                "final_preds = (final_probs >= final_threshold).astype(int)\n",
                "\n",
                "# ---- Generate submission.csv ----\n",
                "submission = pd.DataFrame({\"isic_id\": isic_ids, \"target\": final_preds})\n",
                "output_path = os.path.join(OUTPUT_DIR, \"submission.csv\")\n",
                "submission.to_csv(output_path, index=False)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"SUBMISSION GENERATED: {output_path}\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"  Samples: {len(submission)}\")\n",
                "print(f\"  Malignant: {final_preds.sum()} ({final_preds.mean()*100:.2f}%)\")\n",
                "print(f\"  Benign: {len(final_preds) - final_preds.sum()}\")\n",
                "print(f\"  Models\\u00d7folds: {len(model_configs)}\")\n",
                "print(f\"  Strategy: {ENSEMBLE_STRATEGY}\")\n",
                "print(f\"\\nFirst 10 rows:\")\n",
                "print(submission.head(10).to_string(index=False))\n",
                "print(f\"\\n\\u2705 Ready for submission!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
